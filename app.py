import streamlit as st
import cv2
import numpy as np
from detect_ocr import detect_and_ocr

st.set_page_config(page_title="OCR Biá»ƒn Sá»‘ Xe", page_icon="ğŸš—", layout="centered")
st.markdown("<h1 style='text-align: center; color: #0066cc;'>ğŸš— Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng AI</h1>", unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh xe cáº§n nháº­n diá»‡n", type=["jpg", "png"])

if uploaded_file:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, 1)

    st.markdown("### áº¢nh gá»‘c")
    st.image(image, channels="BGR", use_container_width=True)

    st.divider()
    st.markdown("### Káº¿t quáº£ nháº­n diá»‡n biá»ƒn sá»‘:")

    results = detect_and_ocr(image)

    if not results:
        st.warning("âŒ KhÃ´ng tÃ¬m tháº¥y biá»ƒn sá»‘ nÃ o trong áº£nh.")
    else:
        for i, r in enumerate(results):
            crop = r["crop"]
            text = r["text_cleaned"]

            col1, col2 = st.columns([1, 2])

            with col1:
                st.image(crop, caption=f"ğŸ“· Crop #{i+1}", use_container_width=True)

            with col2:
                # Hiá»ƒn thá»‹ biá»ƒn sá»‘ lá»›n, rÃµ rÃ ng
                plate_display = np.ones((100, 400, 3), dtype=np.uint8) * 255
                cv2.putText(plate_display, text, (10, 65), cv2.FONT_HERSHEY_SIMPLEX,
                            2, (0, 0, 0), 4, cv2.LINE_AA)
                st.image(plate_display, caption=f"ğŸ” Biá»ƒn sá»‘ #{i+1}: `{text}`", use_container_width=True)

        st.success(f"âœ… ÄÃ£ phÃ¡t hiá»‡n {len(results)} biá»ƒn sá»‘.")


# import streamlit as st
# import cv2
# import numpy as np
# from detect_ocr import detect_and_ocr

# st.set_page_config(page_title="OCR Biá»ƒn Sá»‘ Xe", page_icon="ğŸš—", layout="centered")
# st.markdown("<h1 style='text-align: center; color: #0066cc;'>ğŸš— Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng AI</h1>", unsafe_allow_html=True)

# uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh xe cáº§n nháº­n diá»‡n", type=["jpg", "png"])

# if uploaded_file:
#     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
#     image = cv2.imdecode(file_bytes, 1)

#     st.markdown("### ğŸ–¼ï¸ áº¢nh gá»‘c")
#     st.image(image, channels="BGR", use_container_width=True)

#     st.divider()
#     st.markdown("### ğŸ§  Káº¿t quáº£ nháº­n diá»‡n biá»ƒn sá»‘:")

#     results = detect_and_ocr(image)

#     if not results:
#         st.warning("âŒ KhÃ´ng tÃ¬m tháº¥y biá»ƒn sá»‘ nÃ o trong áº£nh.")
#     else:
#         for i, r in enumerate(results):
#             crop = r["crop"]
#             text = r["text_cleaned"]

#             col1, col2 = st.columns([1, 2])

#             with col1:
#                 st.image(crop, caption=f"ğŸ“· Crop #{i+1}", use_container_width=True)

#             with col2:
#                 # Hiá»ƒn thá»‹ biá»ƒn sá»‘ lá»›n, rÃµ rÃ ng
#                 plate_display = np.ones((100, 400, 3), dtype=np.uint8) * 255
#                 cv2.putText(plate_display, text, (10, 65), cv2.FONT_HERSHEY_SIMPLEX,
#                             2, (0, 0, 0), 4, cv2.LINE_AA)
#                 st.image(plate_display, caption=f"ğŸ” Biá»ƒn sá»‘ #{i+1}: `{text}`", use_container_width=True)

#         st.success(f"âœ… ÄÃ£ phÃ¡t hiá»‡n {len(results)} biá»ƒn sá»‘.")
